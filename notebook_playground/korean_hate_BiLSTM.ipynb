{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu와 cuda 중 다음 기기로 학습함: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext import data, datasets\n",
    "from torchtext.vocab import Vectors\n",
    "from torchtext.data import TabularDataset\n",
    "from torchtext.data import Iterator\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import random\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# 각종 전역변수들\n",
    "data_path = 'data\\\\korean-hate-speech\\\\labeled'\n",
    "path_train_data = 'data\\\\korean-hate-speech\\\\labeled\\\\train.tsv'\n",
    "path_dev_data = 'data\\\\korean-hate-speech\\\\labeled\\\\dev.tsv'\n",
    "BATCH_SIZE = 256\n",
    "HIDDEN_DIM = 256\n",
    "NUM_LSTM_LAYER = 2\n",
    "n_classes = 3\n",
    "learning_rate = 0.01\n",
    "MAX_LEN = 80\n",
    "\n",
    "# 시드 고정\n",
    "SEED = 5\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# CUDA setting 확인\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"cpu와 cuda 중 다음 기기로 학습함:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (7896, 4)\n",
      "dev data shape: (471, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>contain_gender_bias</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...</td>\n",
       "      <td>True</td>\n",
       "      <td>gender</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  contain_gender_bias  \\\n",
       "0  (현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...                False   \n",
       "1  ....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...                False   \n",
       "2  ...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...                False   \n",
       "3                 1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데                False   \n",
       "4  1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...                 True   \n",
       "\n",
       "     bias  hate  \n",
       "0  others  hate  \n",
       "1    none  none  \n",
       "2    none  hate  \n",
       "3    none  none  \n",
       "4  gender  hate  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data read\n",
    "train_data = pd.read_csv(path_train_data, sep='\\t')\n",
    "dev_data = pd.read_csv(path_dev_data, sep='\\t')\n",
    "\n",
    "print(\"train data shape: {}\".format(train_data.shape))\n",
    "print(\"dev data shape: {}\".format(dev_data.shape))\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchtext dataset 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고자료  \n",
    "https://wikidocs.net/65348  \n",
    "https://wikidocs.net/64904  \n",
    "\n",
    "--------------------------------------\n",
    "\n",
    "elmo 임베딩\n",
    "https://github.com/HIT-SCIR/ELMoForManyLangs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torchtext를 이용한 전처리\n",
    "\n",
    "gensim word2vec_kor를 불러내서 torch에서 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_label(label, only_hate=False):\n",
    "    if only_hate is True:\n",
    "        label_matching = {'none':0, 'offensive':1, 'hate':1}\n",
    "    else:\n",
    "        label_matching = {'none':0, 'offensive':1, 'hate':2}\n",
    "    \n",
    "    return label_matching[label]\n",
    "\n",
    "def preprocess_bias(bias):\n",
    "    label_matching = {'none':0, 'others':1, 'gender':2}\n",
    "    \n",
    "    return label_matching[bias]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필드 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Mecab('C:\\mecab\\mecab-ko-dic')\n",
    "\n",
    "# comments, hate 만 사용할 거임\n",
    "comments = data.Field(sequential=True,\n",
    "                      use_vocab=True,\n",
    "                      tokenize=tokenizer.morphs,\n",
    "                      lower=True,\n",
    "                      batch_first=True, \n",
    "                      fix_length = MAX_LEN)\n",
    "\n",
    "contain_gender_bias = data.Field(sequential=False,\n",
    "                                 use_vocab=False,\n",
    "                                 batch_first=True, \n",
    "                                 preprocessing=lambda x: x =='True')\n",
    "\n",
    "bias = data.Field(sequential=False,\n",
    "                  use_vocab=False,\n",
    "                  batch_first=True, \n",
    "                  preprocessing=lambda x:preprocess_bias(x))\n",
    "\n",
    "hate = data.Field(sequential=False,\n",
    "                  use_vocab=False,\n",
    "                  is_target=True,\n",
    "                  batch_first=True, \n",
    "                  preprocessing=lambda x:preprocess_label(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 본격적인 데이터셋 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 개수 : 6317\n",
      "검증 샘플의 개수 : 471\n",
      "테스트 샘플의 개수 : 1579\n",
      "{'comments': ['오창', '이채', '은', '이제', '그만', '좀', '나와라', '너무', '설정', '에', '집착', '진심', '도', '없', '구', '~', '너무', '애', '여우', '같', '아', '싫증'], 'contain_gender_bias': False, 'bias': 1, 'hate': 1}\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = TabularDataset.splits(\n",
    "    path=data_path, train='train.tsv', validation='dev.tsv', format='tsv',\n",
    "    fields=[('comments', comments), ('contain_gender_bias', contain_gender_bias), ('bias', bias), ('hate', hate)],\n",
    "    skip_header=True)\n",
    "\n",
    "train_data, test_data = train_data.split(split_ratio=0.8)\n",
    "\n",
    "print('훈련 샘플의 개수 : {}'.format(len(train_data)))\n",
    "print('검증 샘플의 개수 : {}'.format(len(val_data)))\n",
    "print('테스트 샘플의 개수 : {}'.format(len(test_data)))\n",
    "print(vars(train_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어 집합 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_word2vec_kor = './data/word2vec_kor/ko.bin'\n",
    "model_kor_word2vec = gensim.models.Word2Vec.load(path_word2vec_kor)\n",
    "gensim_to_torch_kor_word2vec = 'torch_kor_word2vec.wv'\n",
    "model_kor_word2vec.wv.save_word2vec_format(gensim_to_torch_kor_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vectors = Vectors(name=gensim_to_torch_kor_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 4033\n",
      "임베딩 벡터 크기: torch.Size([4033, 200])\n"
     ]
    }
   ],
   "source": [
    "comments.build_vocab(train_data, vectors=vectors, min_freq=3, max_size=10000)\n",
    "#hate.build_vocab(train_data)\n",
    "\n",
    "print('단어 집합의 크기 : {}'.format(len(comments.vocab)))\n",
    "print('임베딩 벡터 크기: {}'.format(comments.vocab.vectors.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 로더 만들기\n",
    "\n",
    "본래 미니 배치 간 샘플 길이가 모두 다르지만, 앞에 torchtext 변수를 선언할때 fix_length를 이용해 통일시켜주었다. CNN에 집어넣어야하기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 미니 배치의 개수 : 25\n",
      "테스트 데이터의 미니 배치의 개수 : 7\n",
      "검증 데이터의 미니 배치의 개수 : 2\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# 다른 방법\n",
    "train_loader = Iterator(dataset=train_data, batch_size = BATCH_SIZE)\n",
    "test_loader = Iterator(dataset=test_data, batch_size = BATCH_SIZE)\n",
    "\n",
    "print('훈련 데이터의 미니 배치 수 : {}'.format(len(train_loader)))\n",
    "print('테스트 데이터의 미니 배치 수 : {}'.format(len(test_loader)))\n",
    "\"\"\"\n",
    "\n",
    "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
    "        (train_data, val_data, test_data), batch_size=BATCH_SIZE,\n",
    "        shuffle=True, repeat=False, sort_within_batch=False, sort_key=lambda x: len(x.comments))\n",
    "\n",
    "print('훈련 데이터의 미니 배치의 개수 : {}'.format(len(train_iter)))\n",
    "print('테스트 데이터의 미니 배치의 개수 : {}'.format(len(test_iter)))\n",
    "print('검증 데이터의 미니 배치의 개수 : {}'.format(len(val_iter)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, pre_embedding, hidden_dim, model_embedding, num_lstm_layer, n_classes, dropout=0.1):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_lstm_layer = num_lstm_layer\n",
    "        self.n_classes = n_classes\n",
    "        self.embedding = nn.Embedding.from_pretrained(pre_embedding, freeze=False)\n",
    "        \n",
    "        # BiLSTM layer 세팅\n",
    "        self.bi_lstm = nn.LSTM(input_size=self.embedding.embedding_dim,\n",
    "                               hidden_size=self.hidden_dim,\n",
    "                               num_layers=self.num_lstm_layer,\n",
    "                               dropout=dropout,\n",
    "                               batch_first=True,\n",
    "                               bidirectional=True)\n",
    "        \n",
    "        # bidirectional 이라서 hidden_dim * 2\n",
    "        self.linear = nn.Linear(self.hidden_dim * 2, self.n_classes)\n",
    "        \"\"\"\n",
    "        self.lin_layers = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim * 2, self.n_classes)\n",
    "        )\n",
    "        \"\"\"\n",
    "        \n",
    "    def forward(self, sents):\n",
    "        # embedding \n",
    "        embedded = self.embedding(sents)\n",
    "        \n",
    "        # lstm 통과\n",
    "        lstm_out, (h_n, c_n) = self.bi_lstm(embedded) # (h_0, c_0) = (0, 0)\n",
    "        \n",
    "        # forward와 backward의 마지막 time-step의 은닉 상태를 가지고 와서 concat\n",
    "        # 이때 모델이 batch_first라는 점에 주의한다. (dimension 순서가 바뀜)\n",
    "        hidden = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim = 1)\n",
    "        out=self.linear(hidden)\n",
    "        #out=self.lin_layers(hidden)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training function 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_iter):\n",
    "    model.train()\n",
    "    \n",
    "    corrects, total_loss = 0, 0\n",
    "    \n",
    "    for b, batch in enumerate(train_iter):\n",
    "        # comments 는 x, hate(label)은 y로 두고\n",
    "        x, y = batch.comments.to(DEVICE), batch.hate.to(DEVICE)\n",
    "        # gradient 0으로 세팅해두고\n",
    "        optimizer.zero_grad()\n",
    "        # model 돌리고\n",
    "        prediction = model(x)\n",
    "        # loss 구해서 backprop\n",
    "        loss = criterion(prediction, y)\n",
    "        total_loss = total_loss + loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    size = len(train_iter.dataset)\n",
    "    avg_loss = total_loss / size\n",
    "    \n",
    "    return avg_loss\n",
    "        \n",
    "def evaluate(model, val_iter):\n",
    "    model.eval()\n",
    "    \n",
    "    corrects, total_loss = 0, 0\n",
    "    \n",
    "    for b, batch in enumerate(val_iter):\n",
    "        x, y = batch.comments.to(DEVICE), batch.hate.to(DEVICE)\n",
    "        prediction = model(x)\n",
    "        loss = criterion(prediction, y)\n",
    "        total_loss = total_loss + loss.item()\n",
    "        corrects = corrects + (prediction.max(1)[1].view(y.size()).data == y.data).sum()\n",
    "        \n",
    "        y = y.data\n",
    "        y = y.to(\"cpu\")\n",
    "        y = y.detach().numpy()\n",
    "        p = prediction.max(1)[1].data\n",
    "        p = p.to(\"cpu\")\n",
    "        p = p.detach().numpy()\n",
    "    \n",
    "    print('**** Look only last batch case ****')\n",
    "    print(metrics.classification_report(y,p))\n",
    "        \n",
    "    size = len(val_iter.dataset)\n",
    "    avg_loss = total_loss / size\n",
    "    avg_accuracy = 100.0 * corrects / size\n",
    "    \n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm_model = BiLSTM(comments.vocab.vectors, HIDDEN_DIM, model_kor_word2vec, NUM_LSTM_LAYER, n_classes)\n",
    "print(bilstm_model)\n",
    "bilstm_model = bilstm_model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(bilstm_model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM training / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = None\n",
    "num_epoch = 10\n",
    "\n",
    "print('[STAGE] Train')\n",
    "for i in range(1, num_epoch+1):\n",
    "    train_loss = train(bilstm_model, optimizer, train_iter)\n",
    "    val_loss, val_accuracy = evaluate(bilstm_model, val_iter)\n",
    "    result = (\n",
    "        f'[Epoch: {i}/{num_epoch}] train loss : {train_loss:.4f} '\n",
    "        f'| val loss : {val_loss:.4f} | val accuracy : {val_accuracy:.4f}%'\n",
    "    )\n",
    "    print(result)\n",
    "    \n",
    "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        if not os.path.isdir(\"snapshot\"):\n",
    "            os.makedirs(\"snapshot\")\n",
    "        torch.save(bilstm_model.state_dict(), './snapshot/hate_classification_bilstm.pt')\n",
    "        best_val_loss = val_loss\n",
    "        \n",
    "bilstm_model.load_state_dict(torch.load('./snapshot/hate_classification_bilstm.pt'))\n",
    "test_loss, test_acc = evaluate(bilstm_model, test_iter)\n",
    "result = f'테스트 오차: {test_loss:.4f} | 테스트 정확도: {test_acc:.4f}%'\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
