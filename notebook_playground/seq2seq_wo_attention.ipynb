{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import spacy\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_de(text):\n",
    "    \"\"\"\n",
    "    Tokenizes German text from a string into a list of strings (tokens) and reverses it\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings (tokens)\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "SRC = Field(tokenize = tokenize_de, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), \n",
    "                                                    fields = (SRC, TRG))\n",
    "\n",
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        #self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional=True)\n",
    "        self.fc = nn.Linear(enc_hid_dim *2, dec_hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):     \n",
    "        #src = [src len, batch size]\n",
    "        #print('[ENCODER] encoder src: ', src.shape)\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        #print('[ENCODER] embedded src: ', embedded.shape)\n",
    "        \n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        #print('[ENCODER] outputs src: ', outputs.shape)\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
    "        #print('[ENCODER] hidden src: ', hidden.shape)\n",
    "        \n",
    "        #outputs = [src len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #outputs are always from the top hidden layer\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(enc_hid_dim+emb_dim, dec_hid_dim) \n",
    "        #self.rnn = nn.GRU(emb_dim, dec_hid_dim) \n",
    "        #self.fc_out = nn.Linear(dec_hid_dim, output_dim)\n",
    "        self.fc_out = nn.Linear(dec_hid_dim*2+emb_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, context):\n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        #print('[DECODER] decoder embedded: {}'.format(embedded.shape))\n",
    "        #print('[DECODER] decoder context: {}'.format(context.shape))\n",
    "                \n",
    "        #output, hidden = self.rnn(embedded, hidden.unsqueeze(0))\n",
    "        rnn_input = torch.cat((embedded, context.unsqueeze(0)), dim = 2)\n",
    "        #print('[DECODER] decoder rnn_input: {}'.format(rnn_input.shape))\n",
    "        #print('[DECODER] decoder hidden: {}'.format(hidden.shape))\n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        #print('[DECODER] decoder hidden: {}'.format(hidden.shape))\n",
    "        assert (output == hidden).all()\n",
    "        hidden = hidden.squeeze(0)\n",
    "        \n",
    "        output = torch.cat((embedded.squeeze(0), hidden, context), dim=1)\n",
    "        #print('[DECODER] decoder output: {}'.format(output.shape))\n",
    "        prediction = self.fc_out(output)\n",
    "        \n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        #print('[SEQ2SEQ] src shape:', src.shape)\n",
    "        #print('[SEQ2SEQ] trg shape:', trg.shape)\n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        #print('[SEQ2SEQ] output shape:', outputs.shape)\n",
    "        \n",
    "        context = self.encoder(src)\n",
    "        hidden = context\n",
    "        #print('[SEQ2SEQ] encoder_outputs shape:', encoder_outputs.shape)\n",
    "        #print('[SEQ2SEQ] hidden shape:', hidden.shape)\n",
    "        \n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden = self.decoder(input, hidden, context)\n",
    "            \n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(7855, 256)\n",
      "    (rnn): GRU(256, 512, bidirectional=True)\n",
      "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(5893, 256)\n",
      "    (rnn): GRU(768, 512)\n",
      "    (fc_out): Linear(in_features=1280, out_features=5893, bias=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      ")\n",
      "The model has 15927813 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "            \n",
    "print(model.apply(init_weights))\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print('The model has {} trainable parameters'.format(count_parameters(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        #trg = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Time: 0m 51s\n",
      "\tTrain Loss: 5.1974907866658615 | Train PPL: 180.8179613304805\n",
      "\t Val. Loss: 5.149212002754211 |  Val. PPL: 172.29566829811384\n",
      "Epoch: 2 | Time: 0m 50s\n",
      "\tTrain Loss: 4.748686240108003 | Train PPL: 115.43253423358165\n",
      "\t Val. Loss: 5.210301399230957 |  Val. PPL: 183.14925091915524\n",
      "Epoch: 3 | Time: 0m 50s\n",
      "\tTrain Loss: 4.658639985559271 | Train PPL: 105.49251320951427\n",
      "\t Val. Loss: 5.139114618301392 |  Val. PPL: 170.5646865967537\n",
      "Epoch: 4 | Time: 0m 49s\n",
      "\tTrain Loss: 4.604300916982642 | Train PPL: 99.91311086994024\n",
      "\t Val. Loss: 5.131941020488739 |  Val. PPL: 169.34550233117324\n",
      "Epoch: 5 | Time: 0m 49s\n",
      "\tTrain Loss: 4.515908669795234 | Train PPL: 91.46063579237449\n",
      "\t Val. Loss: 5.196409702301025 |  Val. PPL: 180.6225874864371\n",
      "Epoch: 6 | Time: 0m 49s\n",
      "\tTrain Loss: 4.495446869980396 | Train PPL: 89.60820325545453\n",
      "\t Val. Loss: 5.160942852497101 |  Val. PPL: 174.3287444348803\n",
      "Epoch: 7 | Time: 0m 49s\n",
      "\tTrain Loss: 4.4838172045048115 | Train PPL: 88.57212612031996\n",
      "\t Val. Loss: 5.352432727813721 |  Val. PPL: 211.12127424365525\n",
      "Epoch: 8 | Time: 0m 49s\n",
      "\tTrain Loss: 4.440115227048093 | Train PPL: 84.78471060292094\n",
      "\t Val. Loss: 5.292105436325073 |  Val. PPL: 198.76146478529532\n",
      "Epoch: 9 | Time: 0m 52s\n",
      "\tTrain Loss: 4.405735889720496 | Train PPL: 81.91940431509393\n",
      "\t Val. Loss: 5.315563321113586 |  Val. PPL: 203.47910492580647\n",
      "Epoch: 10 | Time: 0m 51s\n",
      "\tTrain Loss: 4.406212983152415 | Train PPL: 81.95849684949351\n",
      "\t Val. Loss: 5.278306782245636 |  Val. PPL: 196.03765972849774\n",
      "Epoch: 11 | Time: 0m 50s\n",
      "\tTrain Loss: 4.375349032196179 | Train PPL: 79.467571453306\n",
      "\t Val. Loss: 5.365249991416931 |  Val. PPL: 213.8446873356995\n",
      "Epoch: 12 | Time: 0m 50s\n",
      "\tTrain Loss: 4.361034829185923 | Train PPL: 78.33815910591464\n",
      "\t Val. Loss: 5.381535291671753 |  Val. PPL: 217.35572382176738\n",
      "Epoch: 13 | Time: 0m 50s\n",
      "\tTrain Loss: 4.321694928643987 | Train PPL: 75.31617571317148\n",
      "\t Val. Loss: 5.1486939787864685 |  Val. PPL: 172.20643812607642\n",
      "Epoch: 14 | Time: 0m 50s\n",
      "\tTrain Loss: 4.3081434172155575 | Train PPL: 74.30241222520084\n",
      "\t Val. Loss: 5.293468594551086 |  Val. PPL: 199.03259286428323\n",
      "Epoch: 15 | Time: 0m 50s\n",
      "\tTrain Loss: 4.346404274129657 | Train PPL: 77.20037188093285\n",
      "\t Val. Loss: 5.251521110534668 |  Val. PPL: 190.85636139290978\n",
      "Epoch: 16 | Time: 0m 50s\n",
      "\tTrain Loss: 4.3127767798133885 | Train PPL: 74.64748104007467\n",
      "\t Val. Loss: 5.1923463344573975 |  Val. PPL: 179.8901405809963\n",
      "Epoch: 17 | Time: 0m 50s\n",
      "\tTrain Loss: 4.121706417478654 | Train PPL: 61.664377708369166\n",
      "\t Val. Loss: 4.941715359687805 |  Val. PPL: 140.0102115633864\n",
      "Epoch: 18 | Time: 0m 50s\n",
      "\tTrain Loss: 3.856053341852936 | Train PPL: 47.278391030118584\n",
      "\t Val. Loss: 4.608434498310089 |  Val. PPL: 100.32696459914742\n",
      "Epoch: 19 | Time: 0m 50s\n",
      "\tTrain Loss: 3.53865426857566 | Train PPL: 34.420567170282666\n",
      "\t Val. Loss: 4.318974077701569 |  Val. PPL: 75.11153015678015\n",
      "Epoch: 20 | Time: 0m 50s\n",
      "\tTrain Loss: 3.2163260025074827 | Train PPL: 24.936335641877324\n",
      "\t Val. Loss: 4.134157776832581 |  Val. PPL: 62.43698304610161\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 30\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut-model_noAtt.pt')\n",
    "    \n",
    "    print('Epoch: {} | Time: {}m {}s'.format(epoch+1, epoch_mins, epoch_secs))\n",
    "    print('\\tTrain Loss: {} | Train PPL: {}'.format(train_loss, math.exp(train_loss)))\n",
    "    print('\\t Val. Loss: {} |  Val. PPL: {}'.format(valid_loss, math.exp(valid_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 4.061550289392471 | Test PPL: 58.06425774212494 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut-model_noAtt.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print('| Test Loss: {} | Test PPL: {} |'.format(test_loss, math.exp(test_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
    "\n",
    "    model.eval()\n",
    "        \n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('de')\n",
    "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "        \n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "    \n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
    "\n",
    "    src_len = torch.LongTensor([len(src_indexes)]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        hidden = model.encoder(src_tensor)\n",
    "        \n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "    context = hidden\n",
    "    for i in range(max_len):\n",
    "\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            output, hidden = model.decoder(trg_tensor, hidden, context)\n",
    "            #hidden = hidden.squeeze(0)\n",
    "            \n",
    "        pred_token = output.argmax(1).item()\n",
    "        \n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "            break\n",
    "    \n",
    "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
    "    \n",
    "    return trg_tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = ['ein', 'schwarzer', 'hund', 'und', 'ein', 'gefleckter', 'hund', 'kÃ¤mpfen', '.']\n",
      "trg = ['a', 'black', 'dog', 'and', 'a', 'spotted', 'dog', 'are', 'fighting']\n"
     ]
    }
   ],
   "source": [
    "example_idx = 12\n",
    "\n",
    "src = vars(train_data.examples[example_idx])['src']\n",
    "trg = vars(train_data.examples[example_idx])['trg']\n",
    "\n",
    "print('src = {}'.format(src))\n",
    "print('trg = {}'.format(trg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted trg = ['a', 'black', 'and', 'black', 'dog', 'dog', 'dog', 'are', 'running', 'a', 'a', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "translation = translate_sentence(src, SRC, TRG, model, device)\n",
    "\n",
    "print('predicted trg = {}'.format(translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\n",
    "    \n",
    "    trgs = []\n",
    "    pred_trgs = []\n",
    "    \n",
    "    for datum in data:\n",
    "        \n",
    "        src = vars(datum)['src']\n",
    "        trg = vars(datum)['trg']\n",
    "        \n",
    "        pred_trg = translate_sentence(src, src_field, trg_field, model, device, max_len)\n",
    "        \n",
    "        #cut off <eos> token\n",
    "        pred_trg = pred_trg[:-1]\n",
    "        \n",
    "        pred_trgs.append(pred_trg)\n",
    "        trgs.append([trg])\n",
    "        \n",
    "    return bleu_score(pred_trgs, trgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score = 12.77655106449502\n"
     ]
    }
   ],
   "source": [
    "bleu_score = calculate_bleu(test_data, SRC, TRG, model, device)\n",
    "\n",
    "print('BLEU score = {}'.format(bleu_score*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
